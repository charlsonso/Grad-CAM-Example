{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_Grad_CAM.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "juyVfZku5917",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0de2c1df-7f0b-43c5-f3ea-533489fb60b8"
      },
      "cell_type": "code",
      "source": [
        "# Run this first\n",
        "!git clone https://github.com/insikk/Grad-CAM-tensorflow.git\n",
        "!mv Grad-CAM-tensorflow/* .\n",
        "!wget ftp://mi.eng.cam.ac.uk/pub/mttt2/models/vgg16.npy\n",
        "!mv vgg16.npy model/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Grad-CAM-tensorflow' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zf0WaP8P6Hja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run this after cloning\n",
        "# Replace vanila relu to guided relu to get guided backpropagation.\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import gen_nn_ops\n",
        "\n",
        "@ops.RegisterGradient(\"GuidedRelu\")\n",
        "def _GuidedReluGrad(op, grad):\n",
        "    return tf.where(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GbeH-Vsc6VUD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from model import vgg16\n",
        "import utils\n",
        "\n",
        "# Get normalized input. VGG network handles the normalized image internally. \n",
        "img1 = utils.load_image(\"./demo.png\")\n",
        "img2 = utils.load_image(\"./shihtzu_mypuppy.jpg\")\n",
        "\n",
        "# Load this image and add to visualization\n",
        "img3 = utils.load_image(\"./tiger.jpg\")\n",
        "\n",
        "\n",
        "batch1_img = img1.reshape((1, 224, 224, 3))\n",
        "batch1_label = np.array([1 if i == 242 else 0 for i in range(1000)])  # 1-hot result for Boxer\n",
        "batch1_label = batch1_label.reshape(1, -1)\n",
        "\n",
        "batch2_img = img2.reshape((1, 224, 224, 3))\n",
        "batch2_label = np.array([1 if i == 155 else 0 for i in range(1000)])  # 1-hot result for Shih-Tzu\n",
        "batch2_label = batch2_label.reshape(1, -1)\n",
        "\n",
        "#################\n",
        "# ADD CODE HERE #\n",
        "#################\n",
        "\n",
        "\n",
        "##################\n",
        "\n",
        "#####################\n",
        "# MAKE CHANGES HERE #\n",
        "#####################\n",
        "batch_img = np.concatenate((batch1_img, batch2_img), 0)\n",
        "batch_label = np.concatenate((batch1_label, batch2_label), 0)\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "#####################\n",
        "\n",
        "#####################\n",
        "#   RUN CODE        #\n",
        "#####################\n",
        "\n",
        "# for i in range(batch_size):\n",
        "#     print('See visualization of below category')\n",
        "#     utils.print_prob(batch_label[i], './synset.txt')\n",
        "\n",
        "# Create tensorflow graph for evaluation\n",
        "eval_graph = tf.Graph()\n",
        "\n",
        "#[batch_size, ]\n",
        "images = tf.placeholder(\"float\", [batch_size, 224, 224, 3])\n",
        "labels = tf.placeholder(tf.float32, [batch_size, 1000])\n",
        "vgg = vgg16.Vgg16()\n",
        "        \n",
        "vgg.build(images)\n",
        "cost = (-1) * tf.reduce_sum(tf.multiply(labels, tf.log(vgg.prob)), axis=1)\n",
        "print('cost:', cost)\n",
        "# cost = tf.reduce_sum((vgg.prob - labels) ** 2)\n",
        "        \n",
        "        \n",
        "# gradient for partial linearization. We only care about target visualization class. \n",
        "y_c = tf.reduce_sum(tf.multiply(vgg.fc8, labels), axis=1)\n",
        "print('y_c:', y_c)\n",
        "# Get last convolutional layer gradient for generating gradCAM visualization\n",
        "target_conv_layer = vgg.pool5\n",
        "target_conv_layer_grad = tf.gradients(y_c, target_conv_layer)[0]\n",
        "\n",
        "# Guided backpropagtion back to input layer\n",
        "gb_grad = tf.gradients(cost, images)[0]\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "        \n",
        "# Run tensorflow \n",
        "\n",
        "with tf.Session() as sess:    \n",
        "    sess.run(init)\n",
        "    \n",
        "    prob = sess.run(vgg.prob, feed_dict={images: batch_img})\n",
        "    \n",
        "    gb_grad_value, target_conv_layer_value, target_conv_layer_grad_value = sess.run([gb_grad, target_conv_layer, target_conv_layer_grad], feed_dict={images: batch_img, labels: batch_label})\n",
        "    \n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        utils.print_prob(prob[i], './synset.txt')\n",
        "        # VGG16 use BGR internally, so we manually change BGR to RGB\n",
        "        gradBGR = gb_grad_value[i]\n",
        "        gradRGB = np.dstack((\n",
        "            gradBGR[:, :, 2],\n",
        "            gradBGR[:, :, 1],\n",
        "            gradBGR[:, :, 0],\n",
        "        ))\n",
        "        utils.visualize(batch_img[i], target_conv_layer_value[i], target_conv_layer_grad_value[i], gradRGB)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}